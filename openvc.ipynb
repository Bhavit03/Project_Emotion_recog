{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c600ee08",
   "metadata": {},
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180361cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0741f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3401b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_cascade = cv2.CascadeClassifier('C:\\Python Code\\FacialDetection\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61dda33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# face emotion detection in live camera\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(r'C:\\Users\\karnb\\Documents\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"demos4.mp4\")\n",
    "\n",
    "\n",
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe'\n",
    "]\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    \n",
    "    start=time.time()\n",
    "    starttime=time.ctime(start)\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    result = DeepFace.analyze(img_path = frame , actions=['emotion'], enforce_detection=False,detector_backend=backends[1] )\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "        box=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        emotion = result[0]['dominant_emotion']\n",
    "    \n",
    "        txt = str(emotion)\n",
    "    \n",
    "    \n",
    "        cv2.putText(box,txt,(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "    \n",
    "    start=time.time()\n",
    "    starttime=time.ctime(start)  \n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5192084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'emotion': {'angry': 0.03082639304921031, 'disgust': 1.441713692873492e-08, 'fear': 0.03511550021357834, 'happy': 0.009256882913177833, 'sad': 0.07421200862154365, 'surprise': 0.0003493443955449038, 'neutral': 99.85023736953735}, 'dominant_emotion': 'neutral', 'region': {'x': 262, 'y': 200, 'w': 136, 'h': 180}}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055865b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16:53:38'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime.split(' ')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f25a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ece2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=result[0]['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc1d9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f7cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=starttime.split(' ')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b79fe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Time elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Emotion, Time elapsed]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('emotion.csv')\n",
    "# df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488ae61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame({\"Emotion\":\"none\", \"Time elapsed\": 0}, index=[1])\n",
    "# df\n",
    "## temporary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34fb7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e64f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start=time.time()\n",
    "# starttime=time.ctime(start)\n",
    "# print(starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1267fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Time elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>16:53:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion Time elapsed\n",
       "1  neutral     16:53:38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"Emotion\":exp, \"Time elapsed\": time}, index=[1])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88440cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897535e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Time elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>16:53:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion Time elapsed\n",
       "1  neutral     16:53:38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d94a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2efe582",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(r'C:\\Users\\karnb\\Documents\\haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "# df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "   \n",
    "            \n",
    "            \n",
    "    start_time = time.time()\n",
    "    seconds = 4\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    if elapsed_time==seconds:\n",
    "        result = DeepFace.analyze(img_path = frame , actions=['emotion'], enforce_detection=False,detector_backend=backends[1] )\n",
    "        emotion = result[0]['dominant_emotion']\n",
    "        exp=result[0]['dominant_emotion']\n",
    "        time=current_time.split(' ')[-2]\n",
    "        df1 = pd.DataFrame({\"Emotion\":exp, \"Time elapsed\": time}, index=[1])\n",
    "        df = df.append(df1)\n",
    "        \n",
    "#     txt = str(emotion)\n",
    "#     cv2.putText(frame,txt,(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "    cv2.imshow('frame',frame)\n",
    "            \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break  \n",
    "    \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406ee04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
